{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7aca68-c187-4d99-b011-68ec096a01b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /disk1/zzl/mmsegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853b3a6f-dd32-4eb0-a2f5-990fd12d49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/disk1/zzl/mmsegmentation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b66f0b-f4b0-44a4-8c69-b6efdaa9b8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/disk1/zzl/mmsegmentation/tools/train.py\", line 16, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/disk1/zzl/mmsegmentation/tools/train.py\", line 16, in <module>\n",
      "    from mmseg.apis import set_random_seed, train_segmentor\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/apis/__init__.py\", line 2, in <module>\n",
      "    from .inference import inference_segmentor, init_segmentor, show_result_pyplot\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/apis/inference.py\", line 9, in <module>\n",
      "        from mmseg.models import build_segmentorfrom mmseg.apis import set_random_seed, train_segmentor\n",
      "\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/models/__init__.py\", line 2, in <module>\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/apis/__init__.py\", line 2, in <module>\n",
      "    from .backbones import *  # noqa: F401,F403\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/models/backbones/__init__.py\", line 2, in <module>\n",
      "    from .inference import inference_segmentor, init_segmentor, show_result_pyplot\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/apis/inference.py\", line 8, in <module>\n",
      "    from .cgnet import CGNet\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/models/backbones/cgnet.py\", line 11, in <module>\n",
      "        from mmseg.datasets.pipelines import Compose\n",
      "from ..builder import BACKBONES  File \"/disk1/zzl/mmsegmentation/mmseg/datasets/__init__.py\", line 2, in <module>\n",
      "\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/models/builder.py\", line 9, in <module>\n",
      "    from .ade import ADE20KDataset\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/datasets/ade.py\", line 8, in <module>\n",
      "    ATTENTION = Registry('attention', parent=MMCV_ATTENTION)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/site-packages/mmcv/utils/registry.py\", line 92, in __init__\n",
      "    from .builder import DATASETS\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/datasets/builder.py\", line 25, in <module>\n",
      "    PIPELINES = Registry('pipeline')\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/site-packages/mmcv/utils/registry.py\", line 92, in __init__\n",
      "    self._scope = self.infer_scope() if scope is None else scope\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/site-packages/mmcv/utils/registry.py\", line 144, in infer_scope\n",
      "    filename = inspect.getmodule(inspect.stack()[2][0]).__name__\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/inspect.py\", line 1526, in stack\n",
      "    self._scope = self.infer_scope() if scope is None else scope\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/site-packages/mmcv/utils/registry.py\", line 144, in infer_scope\n",
      "    filename = inspect.getmodule(inspect.stack()[2][0]).__name__    return getouterframes(sys._getframe(1), context)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/inspect.py\", line 1503, in getouterframes\n",
      "\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/inspect.py\", line 1526, in stack\n",
      "    return getouterframes(sys._getframe(1), context)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/inspect.py\", line 1503, in getouterframes\n",
      "    frameinfo = (frame,) + getframeinfo(frame, context)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
      "    frameinfo = (frame,) + getframeinfo(frame, context)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/inspect.py\", line 1477, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/inspect.py\", line 792, in findsource\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/inspect.py\", line 747, in getmodule\n",
      "    module = getmodule(object, file)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/inspect.py\", line 745, in getmodule\n",
      "    if f == _filesbymodname.get(modname, None):\n",
      "KeyboardInterrupt\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!/disk1/zzl/mmsegmentation/tools/dist_train.sh '/disk1/zzl/mmsegmentation/configs/deeplabv3plus/deeplabv3plus_r50-d8_CPS_2x8_136e_voc12.py' 2 --options model.backbone.with_cp=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1a8d05-19a9-456d-8a01-52d666213b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-11 19:29:09,081 - mmseg - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.8 (default, Apr 13 2021, 19:58:26) [GCC 7.3.0]\n",
      "CUDA available: True\n",
      "GPU 0,1: TITAN Xp\n",
      "CUDA_HOME: /usr/local/cuda-9.2\n",
      "NVCC: Cuda compilation tools, release 9.2, V9.2.88\n",
      "GCC: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\n",
      "PyTorch: 1.7.1+cu92\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.2-Product Build 20210312 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 9.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "TorchVision: 0.8.2+cu92\n",
      "OpenCV: 4.5.3\n",
      "MMCV: 1.3.14\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 9.2\n",
      "MMSegmentation: 0.17.0+ff196c4\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-02-11 19:29:09,082 - mmseg - INFO - Distributed training: False\n",
      "2022-02-11 19:29:09,956 - mmseg - INFO - Config:\n",
      "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='CrossPesudoSupervision',\n",
      "    train_cfg=dict(unsup_weight=1.5),\n",
      "    model=dict(\n",
      "        type='EncoderDecoder',\n",
      "        pretrained='open-mmlab://resnet50_v1c',\n",
      "        backbone=dict(\n",
      "            type='ResNetV1c',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(0, 1, 2, 3),\n",
      "            dilations=(1, 1, 2, 4),\n",
      "            strides=(1, 2, 1, 1),\n",
      "            norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "            norm_eval=False,\n",
      "            style='pytorch',\n",
      "            contract_dilation=True,\n",
      "            with_cp=True),\n",
      "        decode_head=dict(\n",
      "            type='DepthwiseSeparableASPPHead',\n",
      "            in_channels=2048,\n",
      "            in_index=3,\n",
      "            channels=512,\n",
      "            dilations=(1, 12, 24, 36),\n",
      "            c1_in_channels=256,\n",
      "            c1_channels=48,\n",
      "            dropout_ratio=0.1,\n",
      "            num_classes=20,\n",
      "            norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "            align_corners=False,\n",
      "            loss_decode=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
      "        auxiliary_head=dict(\n",
      "            type='FCNHead',\n",
      "            in_channels=1024,\n",
      "            in_index=2,\n",
      "            channels=256,\n",
      "            num_convs=1,\n",
      "            concat_input=False,\n",
      "            dropout_ratio=0.1,\n",
      "            num_classes=20,\n",
      "            norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "            align_corners=False,\n",
      "            loss_decode=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
      "        train_cfg=dict(),\n",
      "        test_cfg=dict(mode='whole')))\n",
      "dataset_type = 'PascalVOCDataset'\n",
      "data_root = '../data/VOCdevkit/VOC2012'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "crop_size = (512, 512)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(2048, 512),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='SemiDataset',\n",
      "        sup=dict(\n",
      "            type='PascalVOCDataset',\n",
      "            data_root='../data/VOCdevkit/VOC2012',\n",
      "            img_dir='JPEGImages',\n",
      "            ann_dir='SegmentationClass',\n",
      "            split=\n",
      "            'ImageSets/Segmentation/semi_partition/pseudoseg_labeled_1-8.txt',\n",
      "            pipeline=[\n",
      "                dict(type='LoadImageFromFile'),\n",
      "                dict(type='LoadAnnotations'),\n",
      "                dict(\n",
      "                    type='Resize',\n",
      "                    img_scale=(2048, 512),\n",
      "                    ratio_range=(0.5, 2.0)),\n",
      "                dict(\n",
      "                    type='RandomCrop',\n",
      "                    crop_size=(512, 512),\n",
      "                    cat_max_ratio=0.75),\n",
      "                dict(type='RandomFlip', prob=0.5),\n",
      "                dict(type='PhotoMetricDistortion'),\n",
      "                dict(\n",
      "                    type='Normalize',\n",
      "                    mean=[123.675, 116.28, 103.53],\n",
      "                    std=[58.395, 57.12, 57.375],\n",
      "                    to_rgb=True),\n",
      "                dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "                dict(type='ExtraAttrs', tag='sup'),\n",
      "                dict(type='DefaultFormatBundle'),\n",
      "                dict(\n",
      "                    type='Collect',\n",
      "                    keys=['img', 'gt_semantic_seg'],\n",
      "                    meta_keys=[\n",
      "                        'filename', 'ori_filename', 'ori_shape', 'img_shape',\n",
      "                        'pad_shape', 'scale_factor', 'flip', 'flip_direction',\n",
      "                        'img_norm_cfg', 'tag'\n",
      "                    ])\n",
      "            ]),\n",
      "        unsup=dict(\n",
      "            type='PascalVOCDataset',\n",
      "            data_root='../data/VOCdevkit/VOC2012',\n",
      "            img_dir='JPEGImages',\n",
      "            ann_dir='SegmentationClass',\n",
      "            split=\n",
      "            'ImageSets/Segmentation/semi_partition/pseudoseg_unlabeled_1-8.txt',\n",
      "            pipeline=[\n",
      "                dict(type='LoadImageFromFile'),\n",
      "                dict(type='Add_Pseudo_gt'),\n",
      "                dict(\n",
      "                    type='Resize',\n",
      "                    img_scale=(2048, 512),\n",
      "                    ratio_range=(0.5, 2.0)),\n",
      "                dict(\n",
      "                    type='RandomCrop',\n",
      "                    crop_size=(512, 512),\n",
      "                    cat_max_ratio=0.75),\n",
      "                dict(type='RandomFlip', prob=0.5),\n",
      "                dict(type='PhotoMetricDistortion'),\n",
      "                dict(\n",
      "                    type='Normalize',\n",
      "                    mean=[123.675, 116.28, 103.53],\n",
      "                    std=[58.395, 57.12, 57.375],\n",
      "                    to_rgb=True),\n",
      "                dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "                dict(type='ExtraAttrs', tag='unsup'),\n",
      "                dict(type='DefaultFormatBundle'),\n",
      "                dict(\n",
      "                    type='Collect',\n",
      "                    keys=['img', 'gt_semantic_seg'],\n",
      "                    meta_keys=[\n",
      "                        'filename', 'ori_filename', 'ori_shape', 'img_shape',\n",
      "                        'pad_shape', 'scale_factor', 'flip', 'flip_direction',\n",
      "                        'img_norm_cfg', 'tag'\n",
      "                    ])\n",
      "            ])),\n",
      "    val=dict(\n",
      "        type='PascalVOCDataset',\n",
      "        data_root='../data/VOCdevkit/VOC2012',\n",
      "        img_dir='JPEGImages',\n",
      "        ann_dir='SegmentationClass',\n",
      "        split='ImageSets/Segmentation/val.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(2048, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='PascalVOCDataset',\n",
      "        data_root='../data/VOCdevkit/VOC2012',\n",
      "        img_dir='JPEGImages',\n",
      "        ann_dir='SegmentationClass',\n",
      "        split='ImageSets/Segmentation/val.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(2048, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    sampler=dict(\n",
      "        train=dict(type='DistributedSemiSampler', sample_ratio=[1, 1])))\n",
      "log_config = dict(\n",
      "    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(\n",
      "    branch1=dict(type='SGD', lr=0.000625, momentum=0.9, weight_decay=0.0005),\n",
      "    branch2=dict(type='SGD', lr=0.000625, momentum=0.9, weight_decay=0.0005))\n",
      "optimizer_config = None\n",
      "lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=True)\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=136)\n",
      "checkpoint_config = dict(by_epoch=True, interval=1)\n",
      "evaluation = dict(metric='mIoU', pre_eval=True)\n",
      "sup_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='ExtraAttrs', tag='sup'),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(\n",
      "        type='Collect',\n",
      "        keys=['img', 'gt_semantic_seg'],\n",
      "        meta_keys=[\n",
      "            'filename', 'ori_filename', 'ori_shape', 'img_shape', 'pad_shape',\n",
      "            'scale_factor', 'flip', 'flip_direction', 'img_norm_cfg', 'tag'\n",
      "        ])\n",
      "]\n",
      "unsup_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Add_Pseudo_gt'),\n",
      "    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='ExtraAttrs', tag='unsup'),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(\n",
      "        type='Collect',\n",
      "        keys=['img', 'gt_semantic_seg'],\n",
      "        meta_keys=[\n",
      "            'filename', 'ori_filename', 'ori_shape', 'img_shape', 'pad_shape',\n",
      "            'scale_factor', 'flip', 'flip_direction', 'img_norm_cfg', 'tag'\n",
      "        ])\n",
      "]\n",
      "work_dir = './work_dirs/deeplabv3plus_r50-d8_CPS_2x8_136e_voc12'\n",
      "gpu_ids = range(0, 1)\n",
      "\n",
      "/disk1/zzl/mmsegmentation/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
      "2022-02-11 19:29:12,067 - mmseg - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://resnet50_v1c'}\n",
      "2022-02-11 19:29:12,067 - mmcv - INFO - load model from: open-mmlab://resnet50_v1c\n",
      "2022-02-11 19:29:12,067 - mmcv - INFO - Use load_from_openmmlab loader\n",
      "2022-02-11 19:29:12,120 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2022-02-11 19:29:12,137 - mmseg - INFO - initialize DepthwiseSeparableASPPHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "2022-02-11 19:29:12,233 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "2022-02-11 19:29:12,248 - mmseg - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'open-mmlab://resnet50_v1c'}\n",
      "2022-02-11 19:29:12,248 - mmcv - INFO - load model from: open-mmlab://resnet50_v1c\n",
      "2022-02-11 19:29:12,249 - mmcv - INFO - Use load_from_openmmlab loader\n",
      "2022-02-11 19:29:12,291 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "2022-02-11 19:29:12,309 - mmseg - INFO - initialize DepthwiseSeparableASPPHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "2022-02-11 19:29:12,405 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "/disk1/zzl/mmsegmentation/tools/train.py:147: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.\n",
      "  warnings.warn(\n",
      "2022-02-11 19:29:12,423 - mmseg - INFO - CrossPesudoSupervision(\n",
      "  (branch1): EncoderDecoder(\n",
      "    (backbone): ResNetV1c(\n",
      "      (stem): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (7): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ReLU(inplace=True)\n",
      "      )\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): ResLayer(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): ResLayer(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): ResLayer(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): ResLayer(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    init_cfg={'type': 'Pretrained', 'checkpoint': 'open-mmlab://resnet50_v1c'}\n",
      "    (decode_head): DepthwiseSeparableASPPHead(\n",
      "      input_transform=None, ignore_index=255, align_corners=False\n",
      "      (loss_decode): CrossEntropyLoss()\n",
      "      (conv_seg): Conv2d(512, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "      (image_pool): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): ConvModule(\n",
      "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (aspp_modules): DepthwiseSeparableASPPModule(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): DepthwiseSeparableConvModule(\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False)\n",
      "            (bn): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (pointwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DepthwiseSeparableConvModule(\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=2048, bias=False)\n",
      "            (bn): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (pointwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): DepthwiseSeparableConvModule(\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=2048, bias=False)\n",
      "            (bn): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (pointwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bottleneck): ConvModule(\n",
      "        (conv): Conv2d(2560, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (c1_bottleneck): ConvModule(\n",
      "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): _BatchNormXd(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (sep_bottleneck): Sequential(\n",
      "        (0): DepthwiseSeparableConvModule(\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2d(560, 560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=560, bias=False)\n",
      "            (bn): _BatchNormXd(560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (pointwise_conv): ConvModule(\n",
      "            (conv): Conv2d(560, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DepthwiseSeparableConvModule(\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (pointwise_conv): ConvModule(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "    (auxiliary_head): FCNHead(\n",
      "      input_transform=None, ignore_index=255, align_corners=False\n",
      "      (loss_decode): CrossEntropyLoss()\n",
      "      (conv_seg): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "      (convs): Sequential(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "  )\n",
      "  (branch2): EncoderDecoder(\n",
      "    (backbone): ResNetV1c(\n",
      "      (stem): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): _BatchNormXd(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (7): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (8): ReLU(inplace=True)\n",
      "      )\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): ResLayer(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): ResLayer(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): ResLayer(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): ResLayer(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "          (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
      "          (bn2): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    init_cfg={'type': 'Pretrained', 'checkpoint': 'open-mmlab://resnet50_v1c'}\n",
      "    (decode_head): DepthwiseSeparableASPPHead(\n",
      "      input_transform=None, ignore_index=255, align_corners=False\n",
      "      (loss_decode): CrossEntropyLoss()\n",
      "      (conv_seg): Conv2d(512, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "      (image_pool): Sequential(\n",
      "        (0): AdaptiveAvgPool2d(output_size=1)\n",
      "        (1): ConvModule(\n",
      "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (aspp_modules): DepthwiseSeparableASPPModule(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): DepthwiseSeparableConvModule(\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False)\n",
      "            (bn): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (pointwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DepthwiseSeparableConvModule(\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=2048, bias=False)\n",
      "            (bn): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (pointwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): DepthwiseSeparableConvModule(\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=2048, bias=False)\n",
      "            (bn): _BatchNormXd(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (pointwise_conv): ConvModule(\n",
      "            (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (bottleneck): ConvModule(\n",
      "        (conv): Conv2d(2560, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (c1_bottleneck): ConvModule(\n",
      "        (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): _BatchNormXd(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "      (sep_bottleneck): Sequential(\n",
      "        (0): DepthwiseSeparableConvModule(\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2d(560, 560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=560, bias=False)\n",
      "            (bn): _BatchNormXd(560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (pointwise_conv): ConvModule(\n",
      "            (conv): Conv2d(560, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DepthwiseSeparableConvModule(\n",
      "          (depthwise_conv): ConvModule(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "          (pointwise_conv): ConvModule(\n",
      "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (activate): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "    (auxiliary_head): FCNHead(\n",
      "      input_transform=None, ignore_index=255, align_corners=False\n",
      "      (loss_decode): CrossEntropyLoss()\n",
      "      (conv_seg): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "      (convs): Sequential(\n",
      "        (0): ConvModule(\n",
      "          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activate): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "  )\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n",
      "2022-02-11 19:29:12,431 - mmseg - INFO - Loaded 183 images\n",
      "2022-02-11 19:29:12,432 - mmseg - INFO - Loaded 1282 images\n",
      "2022-02-11 19:29:15,106 - mmseg - INFO - Loaded 1449 images\n",
      "2022-02-11 19:29:15,106 - mmseg - INFO - Start running, host: zzl@mustdl-3, work_dir: /disk1/zzl/mmsegmentation/ipynb/work_dirs/deeplabv3plus_r50-d8_CPS_2x8_136e_voc12\n",
      "2022-02-11 19:29:15,106 - mmseg - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-02-11 19:29:15,106 - mmseg - INFO - workflow: [('train', 1)], max: 136 epochs\n",
      "2022-02-11 19:30:42,170 - mmseg - INFO - Iter [50/49776]\tlr_branch1: 6.250e-04 lr_branch2: 6.250e-04, eta: 1 day, 0:03:01, time: 1.741, data_time: 0.049, memory: 10229, unsup_loss1: 0.9504, unsup_loss2: 0.9478, cps_loss: 1.8982, sup_loss1: 1.6929, sup_loss2: 1.6895, supervised_loss: 3.3824\n",
      "2022-02-11 19:32:06,959 - mmseg - INFO - Iter [100/49776]\tlr_branch1: 6.250e-04 lr_branch2: 6.250e-04, eta: 23:42:46, time: 1.696, data_time: 0.002, memory: 10229, unsup_loss1: 0.2235, unsup_loss2: 0.2231, cps_loss: 0.4465, sup_loss1: 1.6478, sup_loss2: 1.6503, supervised_loss: 3.2981\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/disk1/zzl/mmsegmentation/tools/train.py\", line 183, in <module>\n",
      "    main()\n",
      "  File \"/disk1/zzl/mmsegmentation/tools/train.py\", line 172, in main\n",
      "    train_segmentor(\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/apis/train.py\", line 121, in train_segmentor\n",
      "    runner.run(data_loaders, cfg.workflow)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 127, in run\n",
      "    epoch_runner(data_loaders[i], **kwargs)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 50, in train\n",
      "    self.run_iter(data_batch, train_mode=True, **kwargs)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 29, in run_iter\n",
      "    outputs = self.model.train_step(data_batch, self.optimizer,\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/site-packages/mmcv/parallel/data_parallel.py\", line 67, in train_step\n",
      "    return self.module.train_step(*inputs[0], **kwargs[0])\n",
      "  File \"/disk1/zzl/mmsegmentation/mmseg/models/segmentors/CPS.py\", line 85, in train_step\n",
      "    optimizer[\"branch1\"].step()\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/zzl/anaconda3/lib/python3.8/site-packages/torch/optim/sgd.py\", line 112, in step\n",
      "    p.add_(d_p, alpha=-group['lr'])\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python /disk1/zzl/mmsegmentation/tools/train.py '/disk1/zzl/mmsegmentation/configs/deeplabv3plus/deeplabv3plus_r50-d8_CPS_2x8_136e_voc12.py' --options model.backbone.with_cp=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d3021-f32a-4716-bdbe-ce357d7d127e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
