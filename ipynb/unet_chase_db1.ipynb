{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f832f32-2475-436d-9f98-0d9e2b79828b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-21 16:06:31,835 - mmseg - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.12 (default, Oct 12 2021, 13:49:34) [GCC 7.5.0]\n",
      "CUDA available: True\n",
      "GPU 0,1,2: GeForce GTX 1080 Ti\n",
      "CUDA_HOME: :/disk1/zzl/cuda-10.2:/home/zzl/cuda-10.2\n",
      "GCC: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\n",
      "PyTorch: 1.9.0\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "TorchVision: 0.10.0\n",
      "OpenCV: 4.5.5\n",
      "MMCV: 1.3.13\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 10.2\n",
      "MMSegmentation: 0.17.0+4461423\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-02-21 16:06:31,835 - mmseg - INFO - Distributed training: False\n",
      "2022-02-21 16:06:32,022 - mmseg - INFO - Config:\n",
      "norm_cfg = dict(type='BN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    pretrained=None,\n",
      "    backbone=dict(\n",
      "        type='UNet',\n",
      "        in_channels=3,\n",
      "        base_channels=64,\n",
      "        num_stages=5,\n",
      "        strides=(1, 1, 1, 1, 1),\n",
      "        enc_num_convs=(2, 2, 2, 2, 2),\n",
      "        dec_num_convs=(2, 2, 2, 2),\n",
      "        downsamples=(True, True, True, True),\n",
      "        enc_dilations=(1, 1, 1, 1, 1),\n",
      "        dec_dilations=(1, 1, 1, 1),\n",
      "        with_cp=False,\n",
      "        conv_cfg=None,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        act_cfg=dict(type='ReLU'),\n",
      "        upsample_cfg=dict(type='InterpConv'),\n",
      "        norm_eval=False),\n",
      "    decode_head=dict(\n",
      "        type='FCNHead',\n",
      "        in_channels=64,\n",
      "        in_index=4,\n",
      "        channels=64,\n",
      "        num_convs=1,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=2,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
      "    auxiliary_head=dict(\n",
      "        type='FCNHead',\n",
      "        in_channels=128,\n",
      "        in_index=3,\n",
      "        channels=64,\n",
      "        num_convs=1,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=2,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='slide', crop_size=(128, 128), stride=(85, 85)))\n",
      "dataset_type = 'ChaseDB1Dataset'\n",
      "data_root = 'data/CHASE_DB1'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "img_scale = (960, 999)\n",
      "crop_size = (128, 128)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='Resize', img_scale=(960, 999), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(128, 128), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(128, 128), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(960, 999),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='RepeatDataset',\n",
      "        times=40000,\n",
      "        dataset=dict(\n",
      "            type='ChaseDB1Dataset',\n",
      "            data_root='data/CHASE_DB1',\n",
      "            img_dir='images/training',\n",
      "            ann_dir='annotations/training',\n",
      "            pipeline=[\n",
      "                dict(type='LoadImageFromFile'),\n",
      "                dict(type='LoadAnnotations'),\n",
      "                dict(\n",
      "                    type='Resize',\n",
      "                    img_scale=(960, 999),\n",
      "                    ratio_range=(0.5, 2.0)),\n",
      "                dict(\n",
      "                    type='RandomCrop',\n",
      "                    crop_size=(128, 128),\n",
      "                    cat_max_ratio=0.75),\n",
      "                dict(type='RandomFlip', prob=0.5),\n",
      "                dict(type='PhotoMetricDistortion'),\n",
      "                dict(\n",
      "                    type='Normalize',\n",
      "                    mean=[123.675, 116.28, 103.53],\n",
      "                    std=[58.395, 57.12, 57.375],\n",
      "                    to_rgb=True),\n",
      "                dict(type='Pad', size=(128, 128), pad_val=0, seg_pad_val=255),\n",
      "                dict(type='DefaultFormatBundle'),\n",
      "                dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "            ])),\n",
      "    val=dict(\n",
      "        type='ChaseDB1Dataset',\n",
      "        data_root='data/CHASE_DB1',\n",
      "        img_dir='images/validation',\n",
      "        ann_dir='annotations/validation',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(960, 999),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='ChaseDB1Dataset',\n",
      "        data_root='data/CHASE_DB1',\n",
      "        img_dir='images/validation',\n",
      "        ann_dir='annotations/validation',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(960, 999),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "log_config = dict(\n",
      "    interval=50,\n",
      "    hooks=[\n",
      "        dict(type='TextLoggerHook', by_epoch=False),\n",
      "        dict(type='TensorboardLoggerHook')\n",
      "    ])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=40000)\n",
      "checkpoint_config = dict(by_epoch=False, interval=4000)\n",
      "evaluation = dict(interval=4000, metric='mDice', pre_eval=True)\n",
      "work_dir = './work_dirs/fcn_unet_s5-d16_128x128_40k_chase_db1'\n",
      "gpu_ids = range(0, 1)\n",
      "\n",
      "2022-02-21 16:06:32,369 - mmseg - INFO - initialize UNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
      "2022-02-21 16:06:32,588 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "2022-02-21 16:06:32,589 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "tools/train.py:147: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.\n",
      "  warnings.warn(\n",
      "2022-02-21 16:06:32,592 - mmseg - INFO - EncoderDecoder(\n",
      "  (backbone): UNet(\n",
      "    (encoder): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): ModuleList(\n",
      "      (0): UpConvBlock(\n",
      "        (conv_block): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): InterpConv(\n",
      "          (interp_upsample): Sequential(\n",
      "            (0): Upsample()\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): UpConvBlock(\n",
      "        (conv_block): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): InterpConv(\n",
      "          (interp_upsample): Sequential(\n",
      "            (0): Upsample()\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): UpConvBlock(\n",
      "        (conv_block): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): InterpConv(\n",
      "          (interp_upsample): Sequential(\n",
      "            (0): Upsample()\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): UpConvBlock(\n",
      "        (conv_block): BasicConvBlock(\n",
      "          (convs): Sequential(\n",
      "            (0): ConvModule(\n",
      "              (conv): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): InterpConv(\n",
      "          (interp_upsample): Sequential(\n",
      "            (0): Upsample()\n",
      "            (1): ConvModule(\n",
      "              (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (activate): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
      "  (decode_head): FCNHead(\n",
      "    input_transform=None, ignore_index=255, align_corners=False\n",
      "    (loss_decode): CrossEntropyLoss()\n",
      "    (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "    (convs): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      "  (auxiliary_head): FCNHead(\n",
      "    input_transform=None, ignore_index=255, align_corners=False\n",
      "    (loss_decode): CrossEntropyLoss()\n",
      "    (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
      "    (convs): Sequential(\n",
      "      (0): ConvModule(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activate): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
      ")\n",
      "2022-02-21 16:06:32,595 - mmseg - INFO - Loaded 20 images\n",
      "Password for <zhuzenglingll@gmail.com>: Traceback (most recent call last):\n",
      "  File \"tools/train.py\", line 183, in <module>\n",
      "    main()\n",
      "  File \"tools/train.py\", line 172, in main\n",
      "    train_segmentor(\n",
      "  File \"/home/zzl/.conda/envs/zzl1/lib/python3.8/site-packages/knockknock/email_sender.py\", line 53, in wrapper_sender\n",
      "    yag_sender.send(current_recipient, 'Training has started ðŸŽ¬', contents)\n",
      "  File \"/home/zzl/.conda/envs/zzl1/lib/python3.8/site-packages/yagmail/sender.py\", line 156, in send\n",
      "    self.login()\n",
      "  File \"/home/zzl/.conda/envs/zzl1/lib/python3.8/site-packages/yagmail/sender.py\", line 210, in login\n",
      "    self._login(self.credentials)\n",
      "  File \"/home/zzl/.conda/envs/zzl1/lib/python3.8/site-packages/yagmail/sender.py\", line 228, in _login\n",
      "    password = self.handle_password(self.user, password)\n",
      "  File \"/home/zzl/.conda/envs/zzl1/lib/python3.8/site-packages/yagmail/sender.py\", line 234, in handle_password\n",
      "    return handle_password(user, password)\n",
      "  File \"/home/zzl/.conda/envs/zzl1/lib/python3.8/site-packages/yagmail/password.py\", line 20, in handle_password\n",
      "    password = getpass.getpass(\"Password for <{0}>: \".format(user))\n",
      "  File \"/home/zzl/.conda/envs/zzl1/lib/python3.8/getpass.py\", line 77, in unix_getpass\n",
      "    passwd = _raw_input(prompt, stream, input=input)\n",
      "  File \"/home/zzl/.conda/envs/zzl1/lib/python3.8/getpass.py\", line 146, in _raw_input\n",
      "    line = input.readline()\n",
      "  File \"/home/zzl/.conda/envs/zzl1/lib/python3.8/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/disk1/zzl/mmsegmentation')\n",
    "!python tools/train.py 'configs/unet/fcn_unet_s5-d16_128x128_40k_chase_db1.py' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ffb9bd8-e39f-469c-96f6-3e419bdd1e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.0.0 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/disk1/zzl/mmsegmentation')\n",
    "!tensorboard --logdir 'work_dirs/deeplabv3plus_r50-d8_CPS_2x8_136e_voc12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eedf23a2-2a78-426e-a3f5-8b3a2257c597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-05 17:16:54,427 - mmseg - INFO - Loaded 8 images\n",
      "Use load_from_local loader\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 0.8 task/s, elapsed: 10s, ETA:     0sper class results:\n",
      "\n",
      "+------------+------+-------+\n",
      "|   Class    | IoU  |  Acc  |\n",
      "+------------+------+-------+\n",
      "| background | 97.4 | 98.73 |\n",
      "|   vessel   | 67.0 | 79.68 |\n",
      "+------------+------+-------+\n",
      "Summary:\n",
      "\n",
      "+-------+------+------+\n",
      "|  aAcc | mIoU | mAcc |\n",
      "+-------+------+------+\n",
      "| 97.53 | 82.2 | 89.2 |\n",
      "+-------+------+------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/disk1/zzl/mmsegmentation')\n",
    "!python tools/test.py 'configs/unet/fcn_unet_s5-d16_128x128_40k_chase_db1.py' 'work_dirs/fcn_unet_s5-d16_128x128_40k_chase_db1/iter_36000.pth' --eval 'mIoU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab31b8ab-731f-43bd-8fd6-088fc89fa7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: mmcv-full 1.3.13\n",
      "Uninstalling mmcv-full-1.3.13:\n",
      "  Would remove:\n",
      "    /home/zzl/.conda/envs/zzl1/lib/python3.8/site-packages/mmcv/*\n",
      "    /home/zzl/.conda/envs/zzl1/lib/python3.8/site-packages/mmcv_full-1.3.13.dist-info/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall mmcv-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7b0e9a1-58c4-48e1-b29b-4ecd5688d50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.0.0 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/disk1/zzl')\n",
    "!tensorboard --logdir 'mmsegmentation/work_dirs/fcn_unet_s5-d16_64x64_DML_40k_drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a715871-ff00-4eac-a904-47979ec60bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
